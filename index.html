<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>CL â‰ˆ NSCL</title>

    <!-- Tailwind CSS CDN -->
    <script src="https://cdn.tailwindcss.com"></script>

    <!-- KaTeX CSS + JS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css" />
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js"
      onload="renderMathInElement(document.body, { delimiters: [ {left: '$$', right: '$$', display: true}, {left: '$', right: '$', display: false} ] });"></script>

    <!-- Icons (SVG-based) -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" />

    <style>
      .fade-in-up {
        opacity: 0;
        transform: translateY(20px);
        transition: opacity 0.6s ease-out, transform 0.6s ease-out;
      }
      .fade-in-up.visible {
        opacity: 1;
        transform: translateY(0);
      }
    </style>
  </head>
  <body class="bg-slate-50 text-slate-800">
    <main class="flex flex-col items-center px-4 py-10 min-h-screen">
      <!-- Hero Section -->
      <section id="hero" class="w-full max-w-5xl text-center fade-in-up">
        <h1 class="mb-4 text-4xl font-extrabold leading-tight md:text-5xl">
          Selfâ€‘Supervised Contrastive Learning <br class="hidden md:block" />
          is Approximately Supervised Contrastive Learning
        </h1>
        <div class="mt-2 space-y-1 text-lg font-medium text-slate-700 md:text-2xl">
          <p>
            <a href="https://achleshwar.github.io/" class="hover:underline" target="_blank">Achleshwar Luthra</a>
            Â· <a href="https://people.tamu.edu/~tianbao-yang/" class="hover:underline" target="_blank">Tianbao Yang</a>
            Â· <a href="https://tomergalanti.github.io/index.html" class="hover:underline" target="_blank">Tomer Galanti</a>
          </p>
          <p class="text-slate-500 font-medium">Texas A&amp;M University</p>
        </div>
      </section>

      <!-- Links Section -->
      <section class="mt-10 flex flex-col md:flex-row items-center justify-center gap-8">
        <a href="https://github.com/yourname/paper-code" class="flex flex-col items-center hover:scale-105 transition-transform" target="_blank">
          <i class="fab fa-github text-5xl text-slate-800"></i>
          <span class="mt-2 text-md text-slate-600">Code</span>
        </a>
        <a href="https://arxiv.org/abs/2405.xxxxx" class="flex flex-col items-center hover:scale-105 transition-transform" target="_blank">
          <i class="fas fa-file-pdf text-5xl text-indigo-500"></i>
          <span class="mt-2 text-md text-slate-600">Paper</span>
        </a>
      </section>

      <!-- Overview Section -->
      <section class="mt-20 w-full max-w-4xl text-left">
        <h2 class="text-2xl font-bold mb-4">Overview</h2>
        <p class="text-lg mb-4">
          Despite its empirical success, the principles that make selfâ€‘supervised contrastive learning (CL)
          work remain poorly understood. Several works have observed that CL-trained models exhibit
          properties remarkably similar to supervised ones â€” such as well-formed clusters and
          transferable features â€” even though CL lacks any access to labels.
        </p>

        <!-- Image Grid Placeholders -->
        <div class="overflow-x-auto">
          <div class="grid grid-cols-6 gap-2 mb-4">
            <!-- Top row: DCL -->
            <div class="bg-gray-200 h-24 rounded"></div>
            <div class="bg-gray-200 h-24 rounded"></div>
            <div class="bg-gray-200 h-24 rounded"></div>
            <div class="bg-gray-200 h-24 rounded"></div>
            <div class="bg-gray-200 h-24 rounded"></div>
            <div class="bg-gray-200 h-24 rounded"></div>
          </div>

          <div class="grid grid-cols-6 gap-2 mb-2">
            <!-- Bottom row: NSCL -->
            <div class="bg-gray-300 h-24 rounded"></div>
            <div class="bg-gray-300 h-24 rounded"></div>
            <div class="bg-gray-300 h-24 rounded"></div>
            <div class="bg-gray-300 h-24 rounded"></div>
            <div class="bg-gray-300 h-24 rounded"></div>
            <div class="bg-gray-300 h-24 rounded"></div>
          </div>

          <div class="grid grid-cols-6 text-center text-sm text-slate-500 mt-4">
            <span>Init</span>
            <span>Epoch 10</span>
            <span>Epoch 100</span>
            <span>Epoch 500</span>
            <span>Epoch 1000</span>
            <span>Epoch 2000</span>
          </div>

          <p class="text-sm text-slate-500 text-center max-w-4xl mx-auto italic mt-4">
            <strong>DCL (top)</strong> forms semantic clusters without label supervision, while <strong>NSCL (bottom)</strong> yields tighter, more separable clusters.
          </p>
        </div>

        <p class="mt-6 text-lg">
          This puzzling behavior has raised a fundamental question:
        </p>

        <div class="mx-auto my-8 w-full max-w-3xl rounded-md border border-black bg-indigo-50 px-6 py-4 text-center text-lg italic text-slate-800 shadow-sm">
          <strong>
            How does self-supervised CL learn representations similar to supervised learning, despite lacking explicit supervision?
          </strong>
        </div>

        <p class="text-lg">
          Our work views selfâ€‘supervised contrastive learning (CL) through the lens of its
          supervised counterpart. We show that the popular <strong>CL objective implicitly optimizes a
          negativesâ€‘only supervised contrastive loss (NSCL)</strong>. We also derive a
          new error bound that links the geometric properties of learned representations to downstream fewâ€‘shot performance.
          Extensive experiments confirm the theory and reveal how CL shapes the geometry of learned features.
        </p>
      </section>

      <!-- Key Claims Placeholder -->
      <section class="mt-20 w-full max-w-4xl text-left">
        <h2 class="text-2xl font-bold mb-4">Key Claims</h2>
        <p class="text-lg leading-relaxed">
          This section will summarize the key theoretical and empirical claims from the paper. We'll include LaTeX-rendered formulas using KaTeX, along with plain text and explanations. Coming up next.
        </p>
      </section>

      <!-- Footer -->
      <footer class="mt-20 border-t pt-6 text-center text-sm text-slate-500">
        Â© 2025 Built with ðŸ§  and â˜•. <br />
        Contact: <a href="mailto:luthra@tamu.edu" class="underline">luthra@tamu.edu</a>
        &middot; <a href="mailto:galanti@tamu.edu" class="underline">galanti@tamu.edu</a>
      </footer>
    </main>

    <!-- Animate on Scroll -->
    <script>
      const observer = new IntersectionObserver(
        (entries) => {
          entries.forEach((entry) => {
            if (entry.isIntersecting) {
              entry.target.classList.add('visible');
            }
          });
        },
        { threshold: 0.1 }
      );

      document.querySelectorAll('.fade-in-up').forEach((el) => observer.observe(el));
    </script>
  </body>
</html>
